{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae1bf03-7e54-44f7-99ae-1c5e65135672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import io\n",
    "from py2neo import Graph\n",
    "from neo4j import GraphDatabase, basic_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01c16157-d7fc-48c4-b302-ea21d212ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubmitPMIDList(Pmid,Format,Bioconcept):\n",
    "\n",
    "    # json = {\"Pmids\": Pmid}\n",
    "\n",
    "    json = {}\n",
    "\n",
    "    #\n",
    "    # load pmids\n",
    "    #\n",
    "    with io.open(Inputfile,'r',encoding=\"utf-8\") as file_input:\n",
    "        json = {\"pmids\": [pmid.strip() for pmid in file_input.readlines()]}\n",
    "    \n",
    "    if Bioconcept != \"\": \n",
    "        json[\"concepts\"] = Bioconcept.split(\",\")\n",
    "    \n",
    "    print(json)\n",
    "    r = requests.post(\"https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/\" + Format , json = json)\n",
    "    \n",
    "    res = r.json()\n",
    "    print(res)\n",
    "\n",
    "    pmid = res['id']\n",
    "    res0 = res['passages'][0]['annotations']\n",
    "    res1 = res['passages'][1]['annotations']\n",
    "    \n",
    "    result = {}\n",
    "    result = res0 + res1\n",
    "    \n",
    "    for i in result:\n",
    "        i['Pmid'] = Pmid\n",
    "    return result\n",
    "    \n",
    "    if r.status_code != 200 :\n",
    "        print (\"[Error]: HTTP code \"+ str(r.status_code))\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f89b164-25c6-4431-820b-8ca27db4d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inputfile = \"./pmid\"\n",
    "Format = \"biocjson\"\n",
    "Bioconcept = \"\"\n",
    "res_json=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af1791e6-839a-49e2-a0a4-e460be305b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pmids': ['35900868']}\n",
      "{'_id': '35900868|None', 'id': '35900868', 'infons': {}, 'passages': [{'infons': {'journal': 'J Clin Invest;2022Jul28. doi:10.1172/JCI161908', 'year': '2022', 'type': 'title', 'authors': 'Lone MA, Aaltonen MJ, Zidell A, Pedro HF, Morales Saute JA, Mathew S, Mohassel P, Bonnemann CG, Shoubridge EA, Hornemann T, ', 'section': 'Title'}, 'offset': 0, 'text': 'SPTLC1 variants associated with ALS produce distinct sphingolipid signatures through impaired interaction with ORMDL proteins.', 'sentences': [], 'annotations': [{'id': '2', 'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'}, 'text': 'SPTLC1', 'locations': [{'offset': 0, 'length': 6}]}, {'id': '3', 'infons': {'identifier': 'MESH:D013107', 'type': 'Chemical'}, 'text': 'sphingolipid', 'locations': [{'offset': 53, 'length': 12}]}], 'relations': []}, {'infons': {'type': 'abstract', 'section': 'Abstract'}, 'offset': 127, 'text': 'Amyotrophic lateral sclerosis (ALS) is a progressive neurodegenerative disease affecting motor neurons. Mutations in the SPTLC1 subunit of serine-palmitoyltransferase (SPT), which catalyzes the first step in the de novo synthesis of sphingolipids cause childhood-onset ALS. SPTLC1-ALS variants map to a transmembrane domain that interacts with ORMDL proteins, negative regulators of SPT activity. We show that ORMDL binding to the holoenzyme complex is impaired in cells expressing pathogenic SPTLC1-ALS alleles, resulting in increased sphingolipid synthesis and a distinct lipid signature. C-terminal SPTLC1 variants cause the peripheral sensory neuropathy HSAN1 due to the synthesis of 1-deoxysphingolipids (1-deoxySLs) that form when SPT metabolizes L-alanine instead of L-serine. Limiting L-serine availability in SPTLC1-ALS expressing cells increased 1-deoxySL and shifted the SL profile from an ALS to an HSAN1-like signature. This effect was corroborated in an SPTLC1-ALS pedigree in which the index patient uniquely presented with an HSAN1 phenotype, increased 1-deoxySL levels, and an L-serine deficiency. These data demonstrate how pathogenic variants in different domains of SPTLC1 give rise to distinct clinical presentations that are nonetheless modifiable by substrate availability.', 'sentences': [], 'annotations': [{'id': '31', 'infons': {'identifier': 'MESH:D000690', 'type': 'Disease'}, 'text': 'Amyotrophic lateral sclerosis', 'locations': [{'offset': 127, 'length': 29}]}, {'id': '32', 'infons': {'identifier': 'MESH:D019636', 'type': 'Disease'}, 'text': 'neurodegenerative disease', 'locations': [{'offset': 180, 'length': 25}]}, {'id': '33', 'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'}, 'text': 'SPTLC1', 'locations': [{'offset': 248, 'length': 6}]}, {'id': '34', 'infons': {'identifier': '189', 'type': 'Gene', 'ncbi_homologene': '37251'}, 'text': 'serine-palmitoyltransferase', 'locations': [{'offset': 266, 'length': 27}]}, {'id': '35', 'infons': {'identifier': '189', 'type': 'Gene', 'ncbi_homologene': '37251'}, 'text': 'SPT', 'locations': [{'offset': 295, 'length': 3}]}, {'id': '36', 'infons': {'identifier': 'MESH:D013107', 'type': 'Chemical'}, 'text': 'sphingolipids', 'locations': [{'offset': 360, 'length': 13}]}, {'id': '37', 'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'}, 'text': 'SPTLC1', 'locations': [{'offset': 401, 'length': 6}]}, {'id': '38', 'infons': {'identifier': '189', 'type': 'Gene', 'ncbi_homologene': '37251'}, 'text': 'SPT', 'locations': [{'offset': 510, 'length': 3}]}, {'id': '39', 'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'}, 'text': 'SPTLC1', 'locations': [{'offset': 620, 'length': 6}]}, {'id': '40', 'infons': {'identifier': 'MESH:D013107', 'type': 'Chemical'}, 'text': 'sphingolipid', 'locations': [{'offset': 663, 'length': 12}]}, {'id': '41', 'infons': {'identifier': 'MESH:D008055', 'type': 'Chemical'}, 'text': 'lipid', 'locations': [{'offset': 701, 'length': 5}]}, {'id': '42', 'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'}, 'text': 'SPTLC1', 'locations': [{'offset': 729, 'length': 6}]}, {'id': '43', 'infons': {'identifier': 'MESH:D000699', 'type': 'Disease'}, 'text': 'sensory neuropathy', 'locations': [{'offset': 766, 'length': 18}]}, {'id': '44', 'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'}, 'text': 'HSAN1', 'locations': [{'offset': 785, 'length': 5}]}, {'id': '45', 'infons': {'identifier': 'MESH:C537409', 'type': 'Disease'}, 'text': '1-deoxysphingolipids (1-deoxySLs', 'locations': [{'offset': 815, 'length': 32}]}, {'id': '46', 'infons': {'identifier': '189', 'type': 'Gene', 'ncbi_homologene': '37251'}, 'text': 'SPT', 'locations': [{'offset': 864, 'length': 3}]}, {'id': '47', 'infons': {'identifier': 'MESH:D000409', 'type': 'Chemical'}, 'text': 'L-alanine', 'locations': [{'offset': 880, 'length': 9}]}, {'id': '48', 'infons': {'identifier': 'MESH:D012694', 'type': 'Chemical'}, 'text': 'serine', 'locations': [{'offset': 903, 'length': 6}]}, {'id': '49', 'infons': {'identifier': 'MESH:D012694', 'type': 'Chemical'}, 'text': 'serine', 'locations': [{'offset': 922, 'length': 6}]}, {'id': '50', 'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'}, 'text': 'SPTLC1', 'locations': [{'offset': 945, 'length': 6}]}, {'id': '51', 'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'}, 'text': 'HSAN1', 'locations': [{'offset': 1038, 'length': 5}]}, {'id': '52', 'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'}, 'text': 'SPTLC1', 'locations': [{'offset': 1095, 'length': 6}]}, {'id': '53', 'infons': {'identifier': '9606', 'type': 'Species'}, 'text': 'patient', 'locations': [{'offset': 1134, 'length': 7}]}, {'id': '54', 'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'}, 'text': 'HSAN1', 'locations': [{'offset': 1169, 'length': 5}]}, {'id': '55', 'infons': {'identifier': 'MESH:C000626286', 'type': 'Chemical'}, 'text': '1-deoxySL', 'locations': [{'offset': 1196, 'length': 9}]}, {'id': '56', 'infons': {'identifier': 'MESH:D012694', 'type': 'Chemical'}, 'text': 'serine', 'locations': [{'offset': 1223, 'length': 6}]}, {'id': '57', 'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'}, 'text': 'SPTLC1', 'locations': [{'offset': 1313, 'length': 6}]}], 'relations': []}], 'relations': [], 'pmid': 35900868, 'pmcid': None, 'created': {'$date': 1659402000780}, 'accessions': ['chemical@MESH:D008055', 'chemical@MESH:C000626286', 'disease@MESH:D019636', 'chemical@MESH:D000409', 'gene@189', 'chemical@MESH:D012694', 'species@9606', 'disease@MESH:C537409', 'chemical@MESH:D013107', 'disease@MESH:D000690', 'gene@10558', 'disease@MESH:D000699'], 'journal': 'J Clin Invest', 'year': 2022, 'authors': ['Lone MA', 'Aaltonen MJ', 'Zidell A', 'Pedro HF', 'Morales Saute JA', 'Mathew S', 'Mohassel P', 'Bonnemann CG', 'Shoubridge EA', 'Hornemann T']}\n"
     ]
    }
   ],
   "source": [
    "with io.open(Inputfile,'r',encoding=\"utf-8\") as file_input:\n",
    "    pmidlist = {\"pmids\": [pmid.strip() for pmid in file_input.readlines()]}\n",
    "    \n",
    "for i in pmidlist['pmids']:\n",
    "    res_json.extend(SubmitPMIDList([i], Format, Bioconcept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c9dbdad-d443-4a8f-9fbe-f33e4dcbc648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '2',\n",
       "  'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'},\n",
       "  'text': 'SPTLC1',\n",
       "  'locations': [{'offset': 0, 'length': 6}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '3',\n",
       "  'infons': {'identifier': 'MESH:D013107', 'type': 'Chemical'},\n",
       "  'text': 'sphingolipid',\n",
       "  'locations': [{'offset': 53, 'length': 12}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '31',\n",
       "  'infons': {'identifier': 'MESH:D000690', 'type': 'Disease'},\n",
       "  'text': 'Amyotrophic lateral sclerosis',\n",
       "  'locations': [{'offset': 127, 'length': 29}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '32',\n",
       "  'infons': {'identifier': 'MESH:D019636', 'type': 'Disease'},\n",
       "  'text': 'neurodegenerative disease',\n",
       "  'locations': [{'offset': 180, 'length': 25}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '33',\n",
       "  'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'},\n",
       "  'text': 'SPTLC1',\n",
       "  'locations': [{'offset': 248, 'length': 6}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '34',\n",
       "  'infons': {'identifier': '189', 'type': 'Gene', 'ncbi_homologene': '37251'},\n",
       "  'text': 'serine-palmitoyltransferase',\n",
       "  'locations': [{'offset': 266, 'length': 27}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '35',\n",
       "  'infons': {'identifier': '189', 'type': 'Gene', 'ncbi_homologene': '37251'},\n",
       "  'text': 'SPT',\n",
       "  'locations': [{'offset': 295, 'length': 3}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '36',\n",
       "  'infons': {'identifier': 'MESH:D013107', 'type': 'Chemical'},\n",
       "  'text': 'sphingolipids',\n",
       "  'locations': [{'offset': 360, 'length': 13}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '37',\n",
       "  'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'},\n",
       "  'text': 'SPTLC1',\n",
       "  'locations': [{'offset': 401, 'length': 6}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '38',\n",
       "  'infons': {'identifier': '189', 'type': 'Gene', 'ncbi_homologene': '37251'},\n",
       "  'text': 'SPT',\n",
       "  'locations': [{'offset': 510, 'length': 3}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '39',\n",
       "  'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'},\n",
       "  'text': 'SPTLC1',\n",
       "  'locations': [{'offset': 620, 'length': 6}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '40',\n",
       "  'infons': {'identifier': 'MESH:D013107', 'type': 'Chemical'},\n",
       "  'text': 'sphingolipid',\n",
       "  'locations': [{'offset': 663, 'length': 12}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '41',\n",
       "  'infons': {'identifier': 'MESH:D008055', 'type': 'Chemical'},\n",
       "  'text': 'lipid',\n",
       "  'locations': [{'offset': 701, 'length': 5}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '42',\n",
       "  'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'},\n",
       "  'text': 'SPTLC1',\n",
       "  'locations': [{'offset': 729, 'length': 6}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '43',\n",
       "  'infons': {'identifier': 'MESH:D000699', 'type': 'Disease'},\n",
       "  'text': 'sensory neuropathy',\n",
       "  'locations': [{'offset': 766, 'length': 18}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '44',\n",
       "  'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'},\n",
       "  'text': 'HSAN1',\n",
       "  'locations': [{'offset': 785, 'length': 5}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '45',\n",
       "  'infons': {'identifier': 'MESH:C537409', 'type': 'Disease'},\n",
       "  'text': '1-deoxysphingolipids (1-deoxySLs',\n",
       "  'locations': [{'offset': 815, 'length': 32}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '46',\n",
       "  'infons': {'identifier': '189', 'type': 'Gene', 'ncbi_homologene': '37251'},\n",
       "  'text': 'SPT',\n",
       "  'locations': [{'offset': 864, 'length': 3}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '47',\n",
       "  'infons': {'identifier': 'MESH:D000409', 'type': 'Chemical'},\n",
       "  'text': 'L-alanine',\n",
       "  'locations': [{'offset': 880, 'length': 9}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '48',\n",
       "  'infons': {'identifier': 'MESH:D012694', 'type': 'Chemical'},\n",
       "  'text': 'serine',\n",
       "  'locations': [{'offset': 903, 'length': 6}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '49',\n",
       "  'infons': {'identifier': 'MESH:D012694', 'type': 'Chemical'},\n",
       "  'text': 'serine',\n",
       "  'locations': [{'offset': 922, 'length': 6}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '50',\n",
       "  'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'},\n",
       "  'text': 'SPTLC1',\n",
       "  'locations': [{'offset': 945, 'length': 6}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '51',\n",
       "  'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'},\n",
       "  'text': 'HSAN1',\n",
       "  'locations': [{'offset': 1038, 'length': 5}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '52',\n",
       "  'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'},\n",
       "  'text': 'SPTLC1',\n",
       "  'locations': [{'offset': 1095, 'length': 6}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '53',\n",
       "  'infons': {'identifier': '9606', 'type': 'Species'},\n",
       "  'text': 'patient',\n",
       "  'locations': [{'offset': 1134, 'length': 7}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '54',\n",
       "  'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'},\n",
       "  'text': 'HSAN1',\n",
       "  'locations': [{'offset': 1169, 'length': 5}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '55',\n",
       "  'infons': {'identifier': 'MESH:C000626286', 'type': 'Chemical'},\n",
       "  'text': '1-deoxySL',\n",
       "  'locations': [{'offset': 1196, 'length': 9}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '56',\n",
       "  'infons': {'identifier': 'MESH:D012694', 'type': 'Chemical'},\n",
       "  'text': 'serine',\n",
       "  'locations': [{'offset': 1223, 'length': 6}],\n",
       "  'Pmid': ['35900868']},\n",
       " {'id': '57',\n",
       "  'infons': {'identifier': '10558', 'type': 'Gene', 'ncbi_homologene': '4681'},\n",
       "  'text': 'SPTLC1',\n",
       "  'locations': [{'offset': 1313, 'length': 6}],\n",
       "  'Pmid': ['35900868']}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8997acbf-35f5-47ff-a2e4-7ac06939b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dictionary(dict): \n",
    "    \n",
    "    def __init__(self): \n",
    "        self = dict() \n",
    "          \n",
    "    def add(self, key, value): \n",
    "        self[key] = value \n",
    "\n",
    "dict_list = []\n",
    "\n",
    "for data in res_json:\n",
    "    dict_obj = my_dictionary() \n",
    "    \n",
    "    for key, val in data.items():\n",
    "        if type(val) == dict:    \n",
    "            for k, v in val.items():\n",
    "                dict_obj.add(k, v)\n",
    "        elif type(val) == list:  \n",
    "            for k, v in val[0].items():\n",
    "                dict_obj.add(k, v)\n",
    "        else:\n",
    "            dict_obj.add(key, val)\n",
    "\n",
    "            \n",
    "    dict_list.append(dict_obj)\n",
    "\n",
    "result = []\n",
    "    \n",
    "for item in dict_list:\n",
    "    item = {key: item[key] for key in item.keys() & {'pmid', 'type', 'text'}}\n",
    "    result.append(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98bdbdba-65bc-42b5-917d-6eb438e35ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [dict(t) for t in {tuple(d.items()) for d in result}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d6e083f-4eae-4a45-9e48-cbf133122074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_file = open('./response.csv', 'w', newline='')\n",
    "# csv_writer = csv.writer(data_file)\n",
    "\n",
    "# count = 0\n",
    " \n",
    "# for i in result:\n",
    "#     if count == 0:\n",
    "#         header = i.keys()\n",
    "#         csv_writer.writerow(header)\n",
    "#         count += 1\n",
    " \n",
    "#     csv_writer.writerow(i.values())\n",
    " \n",
    "# data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f44ef90e-d2cb-40ee-97b6-a3e25c004aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'searchinfo': {'search': 'usa'}, 'search': [{'id': 'Q30', 'title': 'Q30', 'pageid': 126, 'display': {'label': {'value': 'United States of America', 'language': 'en'}, 'description': {'value': 'country in North America', 'language': 'en'}}, 'repository': 'wikidata', 'url': '//www.wikidata.org/wiki/Q30', 'concepturi': 'http://www.wikidata.org/entity/Q30', 'label': 'United States of America', 'description': 'country in North America', 'match': {'type': 'alias', 'language': 'en', 'text': 'USA'}, 'aliases': ['USA']}, {'id': 'Q9212', 'title': 'Q9212', 'pageid': 10572, 'display': {'label': {'value': 'United States Army', 'language': 'en'}, 'description': {'value': 'land service branch of the United States Armed Forces', 'language': 'en'}}, 'repository': 'wikidata', 'url': '//www.wikidata.org/wiki/Q9212', 'concepturi': 'http://www.wikidata.org/entity/Q9212', 'label': 'United States Army', 'description': 'land service branch of the United States Armed Forces', 'match': {'type': 'alias', 'language': 'en', 'text': 'USAR'}, 'aliases': ['USAR']}, {'id': 'Q193619', 'title': 'Q193619', 'pageid': 191634, 'display': {'label': {'value': 'Union of South Africa', 'language': 'en'}, 'description': {'value': 'state in southern Africa from 1910 to 1961, predecessor to the Republic of South Africa', 'language': 'en'}}, 'repository': 'wikidata', 'url': '//www.wikidata.org/wiki/Q193619', 'concepturi': 'http://www.wikidata.org/entity/Q193619', 'label': 'Union of South Africa', 'description': 'state in southern Africa from 1910 to 1961, predecessor to the Republic of South Africa', 'match': {'type': 'alias', 'language': 'en', 'text': 'USA'}, 'aliases': ['USA']}, {'id': 'Q248713', 'title': 'Q248713', 'pageid': 241480, 'display': {'label': {'value': 'USA Network', 'language': 'en'}, 'description': {'value': 'American cable television channel', 'language': 'en'}}, 'repository': 'wikidata', 'url': '//www.wikidata.org/wiki/Q248713', 'concepturi': 'http://www.wikidata.org/entity/Q248713', 'label': 'USA Network', 'description': 'American cable television channel', 'match': {'type': 'label', 'language': 'en', 'text': 'USA Network'}}, {'id': 'Q114147', 'title': 'Q114147', 'pageid': 116736, 'display': {'label': {'value': 'Usa', 'language': 'en'}, 'description': {'value': 'city in Ōita Prefecture, Japan', 'language': 'en'}}, 'repository': 'wikidata', 'url': '//www.wikidata.org/wiki/Q114147', 'concepturi': 'http://www.wikidata.org/entity/Q114147', 'label': 'Usa', 'description': 'city in Ōita Prefecture, Japan', 'match': {'type': 'label', 'language': 'en', 'text': 'Usa'}}, {'id': 'Q8175', 'title': 'Q8175', 'pageid': 9464, 'display': {'label': {'value': 'Usa', 'language': 'en'}, 'description': {'value': 'river in Komi Republic, Russia, a tributary of the Pechora', 'language': 'en'}}, 'repository': 'wikidata', 'url': '//www.wikidata.org/wiki/Q8175', 'concepturi': 'http://www.wikidata.org/entity/Q8175', 'label': 'Usa', 'description': 'river in Komi Republic, Russia, a tributary of the Pechora', 'match': {'type': 'label', 'language': 'en', 'text': 'Usa'}}, {'id': 'Q1991472', 'title': 'Q1991472', 'pageid': 1920092, 'display': {'label': {'value': 'United States of Africa', 'language': 'en'}, 'description': {'value': 'political concept similar to the hypothesised United States of Europe', 'language': 'en'}}, 'repository': 'wikidata', 'url': '//www.wikidata.org/wiki/Q1991472', 'concepturi': 'http://www.wikidata.org/entity/Q1991472', 'label': 'United States of Africa', 'description': 'political concept similar to the hypothesised United States of Europe', 'match': {'type': 'alias', 'language': 'en', 'text': 'USA'}, 'aliases': ['USA']}], 'search-continue': 7, 'success': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Q30'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import hashlib\n",
    "from spacy import Language\n",
    "from typing import List\n",
    "import spacy\n",
    "\n",
    "from spacy.tokens import Doc, Span\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def call_wiki_api(item):\n",
    "    url = f\"https://www.wikidata.org/w/api.php?action=wbsearchentities&search={item}&language=en&format=json\"\n",
    "    data = requests.get(url).json()\n",
    "    # Return the first id (Could upgrade this in the future)\n",
    "    print(data)\n",
    "    return data['search'][0]['id']\n",
    "\n",
    "call_wiki_api(\"usa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20f7e7c2-ca46-48d6-9e63-4315d0f4d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(text):\n",
    "    \"\"\"\n",
    "    Function to parse the generated text and extract the triplets\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "\n",
    "    return triplets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "013bf4c6-35ed-4a73-b01f-8e1d36b3e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.factory(\n",
    "    \"rebel\",\n",
    "    requires=[\"doc.sents\"],\n",
    "    assigns=[\"doc._.rel\"],\n",
    "    default_config={\n",
    "        \"model_name\": \"Babelscape/rebel-large\",\n",
    "        \"device\": 0,\n",
    "    },\n",
    ")\n",
    "class RebelComponent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        nlp,\n",
    "        name,\n",
    "        model_name: str,\n",
    "        device: int,\n",
    "    ):\n",
    "        assert model_name is not None, \"\"\n",
    "        self.triplet_extractor = pipeline(\"text2text-generation\", model=model_name, tokenizer=model_name, device=device)\n",
    "        self.entity_mapping = {}\n",
    "        # Register custom extension on the Doc\n",
    "        if not Doc.has_extension(\"rel\"):\n",
    "          Doc.set_extension(\"rel\", default={})\n",
    "\n",
    "    def get_wiki_id(self, item: str):\n",
    "        mapping = self.entity_mapping.get(item)\n",
    "        if mapping:\n",
    "          return mapping\n",
    "        else:\n",
    "          res = call_wiki_api(item)\n",
    "          self.entity_mapping[item] = res\n",
    "          return res\n",
    "\n",
    "    \n",
    "    def _generate_triplets(self, sent: Span) -> List[dict]:\n",
    "          output_ids = self.triplet_extractor(sent.text, return_tensors=True, return_text=False)[0][\"generated_token_ids\"][\"output_ids\"]\n",
    "          extracted_text = self.triplet_extractor.tokenizer.batch_decode(output_ids[0])\n",
    "          extracted_triplets = extract_triplets(extracted_text[0])\n",
    "          return extracted_triplets\n",
    "\n",
    "    def set_annotations(self, doc: Doc, triplets: List[dict]):\n",
    "        for triplet in triplets:\n",
    "\n",
    "            # Remove self-loops (relationships that start and end at the entity)\n",
    "            if triplet['head'] == triplet['tail']:\n",
    "                continue\n",
    "\n",
    "            # Use regex to search for entities\n",
    "            head_span = re.search(triplet[\"head\"], doc.text)\n",
    "            tail_span = re.search(triplet[\"tail\"], doc.text)\n",
    "\n",
    "            # Skip the relation if both head and tail entities are not present in the text\n",
    "            # Sometimes the Rebel model hallucinates some entities\n",
    "            if not head_span or not tail_span:\n",
    "              continue\n",
    "\n",
    "            index = hashlib.sha1(\"\".join([triplet['head'], triplet['tail'], triplet['type']]).encode('utf-8')).hexdigest()\n",
    "            if index not in doc._.rel:\n",
    "                # Get wiki ids and store results\n",
    "                doc._.rel[index] = {\"relation\": triplet[\"type\"], \"head_span\": {'text': triplet['head'], 'id': self.get_wiki_id(triplet['head'])}, \"tail_span\": {'text': triplet['tail'], 'id': self.get_wiki_id(triplet['tail'])}}\n",
    "\n",
    "    def __call__(self, doc: Doc) -> Doc:\n",
    "        for sent in doc.sents:\n",
    "            sentence_triplets = self._generate_triplets(sent)\n",
    "            self.set_annotations(doc, sentence_triplets)\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "878c4afa-2771-47f5-b931-96ab9b9c3104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryan/Git/KG_ALS_Exercise/venv/lib/python3.9/site-packages/spacy/util.py:865: UserWarning: [W095] Model 'en_core_web_sm' (3.3.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.4.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E002] Can't find factory for 'xx_coref' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, ner, beam_ner, entity_ruler, tagger, morphologizer, senter, sentencizer, textcat, spancat, future_entity_ruler, span_ruler, textcat_multilabel, rebel, en.lemmatizer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Add coreference resolution model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m coref \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m'\u001b[39m, disable\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtagger\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattribute_ruler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemmatizer\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m \u001b[43mcoref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxx_coref\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchunk_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchunk_overlap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Define rel extraction model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m rel_ext \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m'\u001b[39m, disable\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemmatizer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattribute_rules\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtagger\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Git/KG_ALS_Exercise/venv/lib/python3.9/site-packages/spacy/language.py:795\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_factory(factory_name):\n\u001b[1;32m    788\u001b[0m         err \u001b[38;5;241m=\u001b[39m Errors\u001b[38;5;241m.\u001b[39mE002\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    789\u001b[0m             name\u001b[38;5;241m=\u001b[39mfactory_name,\n\u001b[1;32m    790\u001b[0m             opts\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactory_names),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    793\u001b[0m             lang_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang,\n\u001b[1;32m    794\u001b[0m         )\n\u001b[0;32m--> 795\u001b[0m     pipe_component \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_pipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfactory_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m pipe_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pipe_index(before, after, first, last)\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipe_meta[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_factory_meta(factory_name)\n",
      "File \u001b[0;32m~/Git/KG_ALS_Exercise/venv/lib/python3.9/site-packages/spacy/language.py:655\u001b[0m, in \u001b[0;36mLanguage.create_pipe\u001b[0;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_factory(factory_name):\n\u001b[1;32m    648\u001b[0m     err \u001b[38;5;241m=\u001b[39m Errors\u001b[38;5;241m.\u001b[39mE002\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    649\u001b[0m         name\u001b[38;5;241m=\u001b[39mfactory_name,\n\u001b[1;32m    650\u001b[0m         opts\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactory_names),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m         lang_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang,\n\u001b[1;32m    654\u001b[0m     )\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[1;32m    656\u001b[0m pipe_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_factory_meta(factory_name)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# This is unideal, but the alternative would mean you always need to\u001b[39;00m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;66;03m# specify the full config settings, which is not really viable.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: [E002] Can't find factory for 'xx_coref' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, ner, beam_ner, entity_ruler, tagger, morphologizer, senter, sentencizer, textcat, spancat, future_entity_ruler, span_ruler, textcat_multilabel, rebel, en.lemmatizer"
     ]
    }
   ],
   "source": [
    "DEVICE = -1 # Number of the GPU, -1 if want to use CPU\n",
    "\n",
    "# Add coreference resolution model\n",
    "coref = spacy.load('en_core_web_sm', disable=['ner', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer'])\n",
    "coref.add_pipe(\n",
    "    \"xx_coref\", config={\"chunk_size\": 2500, \"chunk_overlap\": 2, \"device\": DEVICE})\n",
    "\n",
    "# Define rel extraction model\n",
    "\n",
    "rel_ext = spacy.load('en_core_web_sm', disable=['ner', 'lemmatizer', 'attribute_rules', 'tagger'])\n",
    "rel_ext.add_pipe(\"rebel\", config={\n",
    "    'device':DEVICE, # Number of the GPU, -1 if want to use CPU\n",
    "    'model_name':'Babelscape/rebel-large'} # Model used, will default to 'Babelscape/rebel-large' if not given\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c7532-43ec-4420-9206-abbca76a342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Christian Drosten works in Germany. He likes to work for Google.\"\n",
    "\n",
    "coref_text = coref(input_text)._.resolved_text\n",
    "\n",
    "doc = rel_ext(coref_text)\n",
    "\n",
    "for value, rel_dict in doc._.rel.items():\n",
    "    print(f\"{value}: {rel_dict}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
